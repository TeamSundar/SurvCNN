{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, LSTM, GRU, Embedding, Concatenate, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Convolution2D\n",
    "from keras.regularizers import l2,l1\n",
    "from keras import optimizers, layers, regularizers\n",
    "from keras.optimizers import SGD,Adam,RMSprop\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import math\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "from keras.engine.topology import Layer\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy.random import seed\n",
    "import nnet_survival\n",
    "#calibration\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "#Data process1\n",
    "import os\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sksurv.metrics import concordance_index_censored, concordance_index_ipcw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'process'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2064b73fb050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPHOTOMICS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'process'"
     ]
    }
   ],
   "source": [
    "from process import PHOTOMICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PHOTOMICS():\n",
    "    def __init__(self, omics, PH, clinical):\n",
    "        self.omics = omics\n",
    "        self.PH = PH\n",
    "        self.clinical = clinical\n",
    "    \n",
    "    def start_sess(self):\n",
    "        config = ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        session = InteractiveSession(config=config)\n",
    "    \n",
    "    def architecture(self):\n",
    "        #mrna_input\n",
    "        input_1 = Input(shape = (122,122,1))\n",
    "        mrna_conv_1   = Convolution2D(256, (3, 3), kernel_initializer='glorot_normal')(input_1)\n",
    "        mrna_bn_1     = BatchNormalization()(mrna_conv_1)\n",
    "        mrna_act_1    = Activation('relu')(mrna_bn_1)\n",
    "        mrna_pool_1   = MaxPooling2D(pool_size = (2,2))(mrna_act_1)\n",
    "\n",
    "        mrna_conv_2   = Convolution2D(256, (3, 3), kernel_initializer='glorot_normal')(mrna_pool_1)\n",
    "        mrna_bn_2     = BatchNormalization()(mrna_conv_2)\n",
    "        mrna_act_2    = Activation('relu')(mrna_bn_2)\n",
    "        mrna_pool_2   = MaxPooling2D(pool_size = (2,2))(mrna_act_2)\n",
    "\n",
    "        flat_1 = Flatten()(mrna_pool_2)\n",
    "\n",
    "        #meth_input\n",
    "        input_2 = Input(shape = (122,122,1))\n",
    "        meth_conv_1   = Convolution2D(256, (3, 3), kernel_initializer='glorot_normal')(input_2)\n",
    "        meth_bn_1     = BatchNormalization()(meth_conv_1)\n",
    "        meth_act_1    = Activation('relu')(meth_bn_1)\n",
    "        meth_pool_1   = MaxPooling2D(pool_size = (2,2))(meth_act_1)\n",
    "\n",
    "        meth_conv_2   = Convolution2D(256, (3, 3), kernel_initializer='glorot_normal')(meth_pool_1)\n",
    "        meth_bn_2     = BatchNormalization()(meth_conv_2)\n",
    "        meth_act_2    = Activation('relu')(meth_bn_2)\n",
    "        meth_pool_2   = MaxPooling2D(pool_size = (2,2))(meth_act_2)\n",
    "\n",
    "        flat_2 = Flatten()(meth_pool_2)\n",
    "\n",
    "        #mirna_input\n",
    "        input_3 = Input(shape = (42,42,1))\n",
    "        mirna_conv_1   = Convolution2D(256, (3, 3), kernel_initializer='glorot_normal')(input_3)\n",
    "        mirna_bn_1     = BatchNormalization()(mirna_conv_1)\n",
    "        mirna_act_1    = Activation('relu')(mirna_bn_1)\n",
    "        mirna_pool_1   = MaxPooling2D(pool_size = (2,2))(mirna_act_1)\n",
    "\n",
    "        mirna_conv_2   = Convolution2D(256, (3, 3), kernel_initializer='glorot_normal')(mirna_pool_1)\n",
    "        mirna_bn_2     = BatchNormalization()(mirna_conv_2)\n",
    "        mirna_act_2    = Activation('relu')(mirna_bn_2)\n",
    "        mirna_pool_2   = MaxPooling2D(pool_size = (2,2))(mirna_act_2)\n",
    "\n",
    "        flat_3 = Flatten()(mirna_pool_2)\n",
    "\n",
    "        #clinical_input\n",
    "        input_4 = Input(shape=(22, ), name='clinical')\n",
    "        dense = Dense(1, activation='relu', kernel_initializer='glorot_normal')(input_4)\n",
    "        #flat4 = Flatten()(dense)\n",
    "\n",
    "        if self.omics == 'mrna':\n",
    "            if self.clinical:\n",
    "                concat = Concatenate()([flat_1, dense])\n",
    "            else:\n",
    "                concat = flat_1\n",
    "\n",
    "            dense_1 = Dense(256, activation = 'relu',kernel_initializer='glorot_normal')(concat)\n",
    "            dense_1_dropout = Dropout(0.5)(dense_1)\n",
    "            dense_2 = Dense(128, activation = 'relu',kernel_initializer='glorot_normal')(dense_1_dropout)\n",
    "            dense_2_dropout = Dropout(0.2)(dense_2)     \n",
    "\n",
    "            if self.PH:\n",
    "                dense_3 = Dense(1, use_bias=0, kernel_initializer='zeros')(dense_2_dropout)\n",
    "                output  = nnet_survival.PropHazards(n_intervals)(dense_3)\n",
    "            else:\n",
    "                output = Dense(n_intervals, activation='sigmoid', kernel_initializer='he_normal')(dense_2_dropout)\n",
    "\n",
    "            if self.clinical:\n",
    "                model = Model(inputs=[input_1, input_4], outputs=[output])\n",
    "            else:\n",
    "                model = Model(inputs=[input_1], outputs=[output])\n",
    "        \n",
    "        if self.omics == 'meth':\n",
    "            if self.clinical:\n",
    "                concat = Concatenate()([flat_2, dense])\n",
    "            else:\n",
    "                concat = flat_2\n",
    "\n",
    "            dense_1 = Dense(256, activation = 'relu',kernel_initializer='glorot_normal')(concat)\n",
    "            dense_1_dropout = Dropout(0.5)(dense_1)\n",
    "            dense_2 = Dense(128, activation = 'relu',kernel_initializer='glorot_normal')(dense_1_dropout)\n",
    "            dense_2_dropout = Dropout(0.2)(dense_2)\n",
    "            \n",
    "            if self.PH:\n",
    "                dense_3 = Dense(1, use_bias=0, kernel_initializer='zeros')(dense_2_dropout)\n",
    "                output  = nnet_survival.PropHazards(n_intervals)(dense_3)\n",
    "            else:\n",
    "                output = Dense(n_intervals, activation='sigmoid', kernel_initializer='he_normal')(dense_2_dropout)\n",
    "            \n",
    "            if self.clinical:\n",
    "                model = Model(inputs=[input_2, input_4], outputs=[output])\n",
    "            else:\n",
    "                model = Model(inputs=[input_2], outputs=[output])\n",
    "        \n",
    "        if self.omics == 'mirna':\n",
    "            if self.clinical:\n",
    "                concat = Concatenate()([flat_3, dense])\n",
    "            else:\n",
    "                concat = flat_3\n",
    "\n",
    "            dense_1 = Dense(256, activation = 'relu',kernel_initializer='glorot_normal')(concat)\n",
    "            dense_1_dropout = Dropout(0.5)(dense_1)\n",
    "            dense_2 = Dense(128, activation = 'relu',kernel_initializer='glorot_normal')(dense_1_dropout)\n",
    "            dense_2_dropout = Dropout(0.2)(dense_2)\n",
    "                 \n",
    "            if self.PH:\n",
    "                dense_3 = Dense(1, use_bias=0, kernel_initializer='zeros')(dense_2_dropout)\n",
    "                output  = nnet_survival.PropHazards(n_intervals)(dense_3)\n",
    "            else:\n",
    "                output = Dense(n_intervals, activation='sigmoid', kernel_initializer='he_normal')(dense_2_dropout)\n",
    "\n",
    "            if self.clinical:\n",
    "                model = Model(inputs=[input_3,input_4], outputs=[output])\n",
    "            else:\n",
    "                model = Model(inputs=[input_3], outputs=[output])\n",
    "\n",
    "        if self.omics == 'mrna_meth':\n",
    "            if self.clinical:\n",
    "                concat = Concatenate()([flat_1, flat_2, dense])\n",
    "            else:\n",
    "                concat = Concatenate()([flat_1,flat_2])\n",
    "\n",
    "            dense_1 = Dense(256, activation = 'relu',kernel_initializer='glorot_normal')(concat)\n",
    "            dense_1_dropout = Dropout(0.5)(dense_1)\n",
    "            dense_2 = Dense(128, activation = 'relu',kernel_initializer='glorot_normal')(dense_1_dropout)\n",
    "            dense_2_dropout = Dropout(0.2)(dense_2)    \n",
    "            \n",
    "            if self.PH:\n",
    "                dense_3 = Dense(1, use_bias=0, kernel_initializer='zeros')(dense_2_dropout)\n",
    "                output  = nnet_survival.PropHazards(n_intervals)(dense_3)\n",
    "            else:\n",
    "                output = Dense(n_intervals, activation='sigmoid', kernel_initializer='he_normal')(dense_2_dropout)\n",
    "            \n",
    "            if self.clinical:\n",
    "                model = Model(inputs=[input_1,input_2,input_4], outputs=[output])\n",
    "            else:\n",
    "                model = Model(inputs=[input_1, input_2], outputs=[output])\n",
    "\n",
    "        if self.omics == 'mrna_mirna':\n",
    "            if self.clinical:\n",
    "                concat = Concatenate()([flat_1, flat_3, dense])\n",
    "            else:\n",
    "                concat = Concatenate()([flat_1,flat_3])\n",
    "\n",
    "            dense_1 = Dense(256, activation = 'relu',kernel_initializer='glorot_normal')(concat)\n",
    "            dense_1_dropout = Dropout(0.5)(dense_1)\n",
    "            dense_2 = Dense(128, activation = 'relu',kernel_initializer='glorot_normal')(dense_1_dropout)\n",
    "            dense_2_dropout = Dropout(0.2)(dense_2)\n",
    "            \n",
    "            if self.PH:\n",
    "                dense_3 = Dense(1, use_bias=0, kernel_initializer='zeros')(dense_2_dropout)\n",
    "                output  = nnet_survival.PropHazards(n_intervals)(dense_3)\n",
    "            else:\n",
    "                output = Dense(n_intervals, activation='sigmoid', kernel_initializer='he_normal')(dense_2_dropout)\n",
    "\n",
    "            if self.clinical:\n",
    "                model = Model(inputs=[input_1,input_3,input_4], outputs=[output])\n",
    "            else:\n",
    "                model = Model(inputs=[input_1, input_3], outputs=[output])\n",
    "\n",
    "        if self.omics == 'mrna_meth_mirna':\n",
    "            if self.clinical:\n",
    "                concat = Concatenate()([flat_1, flat_2, flat_3, dense])\n",
    "            else:\n",
    "                concat = Concatenate()([flat_1, flat_2, flat_3])\n",
    "\n",
    "            dense_1 = Dense(512, activation = 'relu',kernel_initializer='glorot_normal')(concat)\n",
    "            dense_1_dropout = Dropout(0.5)(dense_1)\n",
    "            dense_2 = Dense(128, activation = 'relu',kernel_initializer='glorot_normal')(dense_1_dropout)\n",
    "            dense_2_dropout = Dropout(0.1)(dense_2)\n",
    "            \n",
    "            if self.PH:\n",
    "                dense_3 = Dense(1, use_bias=0, kernel_initializer='zeros')(dense_2)\n",
    "                output  = nnet_survival.PropHazards(n_intervals)(dense_3)\n",
    "            else:\n",
    "                output = Dense(n_intervals, activation='sigmoid', kernel_initializer='he_normal')(dense_2)\n",
    "\n",
    "            if self.clinical:\n",
    "                model = Model(inputs=[input_1,input_2,input_3,input_4], outputs=[output])\n",
    "            else:\n",
    "                model = Model(inputs=[input_1,input_2,input_3], outputs=[output])\n",
    "\n",
    "        return model\n",
    "\n",
    "    # Reset Keras Session\n",
    "    def reset_keras(self):\n",
    "        print(\"Restarting Keras Session...\")\n",
    "        sess = get_session()\n",
    "        clear_session()\n",
    "        sess.close()\n",
    "        sess = get_session()\n",
    "        try:\n",
    "            del model\n",
    "        except:\n",
    "            pass\n",
    "        config = ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        session = InteractiveSession(config=config)\n",
    "        print('Done!')\n",
    "\n",
    "    #Process Data\n",
    "    #Select common patients based on the number and type of omics under observation\n",
    "    #Choices of omics: [mrna, meth, mirna, mrna_meth, mrna_mirna, mrna_meth_mirna]\n",
    "\n",
    "    def input_process1(self, path_omics1, path_omics2, path_omics3):\n",
    "        print('Data processing-I...')\n",
    "        #training_list = os.listdir('data/' + path)\n",
    "        training_list1 = os.listdir('data/' + path_omics1)\n",
    "        training_list2 = os.listdir('data/' + path_omics2)\n",
    "        training_list3 = os.listdir('data/' + path_omics3)\n",
    "\n",
    "        if self.omics=='mrna':      #for only mRNA data\n",
    "            training_list=training_list1\n",
    "            shape = (len(training_list), 122, 122, 1)\n",
    "            shape_mirna = (len(training_list), 42, 42, 1)        \n",
    "\n",
    "            dataset1 = np.ndarray(shape=shape,dtype=np.float32)\n",
    "            dataset2 = np.ndarray(shape=shape,dtype=np.float32)\n",
    "            dataset3 = np.ndarray(shape=shape_mirna,dtype=np.float32)\n",
    "            i=0\n",
    "            for item in training_list:\n",
    "                img1 = load_img(\"data/\" + path_omics1 + '/' + item, target_size=(122,122), color_mode='grayscale')  # this is a PIL image\n",
    "                # Convert to Numpy Array\n",
    "                x1 = img_to_array(img1) \n",
    "                dataset1[i] = x1\n",
    "                i += 1\n",
    "                if i % 100 == 0:\n",
    "                    print(\"%d images to array\" % i)\n",
    "            print(\"All mrna images done!\")\n",
    "        \n",
    "        elif self.omics=='meth':      #for only Methylation data\n",
    "            training_list=training_list2\n",
    "            shape = (len(training_list), 122, 122, 1)\n",
    "            shape_mirna = (len(training_list), 42, 42, 1)        \n",
    "\n",
    "            dataset1 = np.ndarray(shape=shape,dtype=np.float32)\n",
    "            dataset2 = np.ndarray(shape=shape,dtype=np.float32)\n",
    "            dataset3 = np.ndarray(shape=shape_mirna,dtype=np.float32)\n",
    "            i=0\n",
    "            for item in training_list:\n",
    "                img2 = load_img(\"data/\" + path_omics2 + '/' + item, target_size=(122,122), color_mode='grayscale')  # this is a PIL image\n",
    "                # Convert to Numpy Array\n",
    "                x2 = img_to_array(img2) \n",
    "                dataset2[i] = x2\n",
    "                i += 1\n",
    "                if i % 100 == 0:\n",
    "                    print(\"%d images to array\" % i)\n",
    "            print(\"All meth images done!\")  \n",
    "\n",
    "        elif self.omics=='mirna':     #for only miRNA data\n",
    "            training_list=training_list3\n",
    "            shape = (len(training_list), 122, 122, 1)\n",
    "            shape_mirna = (len(training_list), 42, 42, 1)        \n",
    "\n",
    "            dataset1 = np.ndarray(shape=shape,dtype=np.float32)\n",
    "            dataset2 = np.ndarray(shape=shape,dtype=np.float32)\n",
    "            dataset3 = np.ndarray(shape=shape_mirna,dtype=np.float32)\n",
    "            i=0\n",
    "            for item in training_list:\n",
    "                img3 = load_img(\"data/\" + path_omics3 + '/' + item, target_size=(42,42), color_mode='grayscale')  # this is a PIL image\n",
    "                # Convert to Numpy Array\n",
    "                x3 = img_to_array(img3) \n",
    "                dataset3[i] = x3\n",
    "                i += 1\n",
    "                if i % 100 == 0:\n",
    "                    print(\"%d images to array\" % i)\n",
    "            print(\"All mirna images done!\")       \n",
    "\n",
    "        elif self.omics=='mrna_meth':     #for mRNA and Methylation omics\n",
    "            training_list=np.intersect1d(training_list1,training_list2)\n",
    "            print('mRNA_meth common patients:', len(training_list))\n",
    "            training_list.sort()\n",
    "            training_list = np.asarray(training_list, dtype=object)\n",
    "\n",
    "            shape = (len(training_list), 122, 122, 1)\n",
    "            shape_mirna = (len(training_list), 42, 42, 1)        \n",
    "\n",
    "            dataset1 = np.ndarray(shape=shape,dtype=np.float32)\n",
    "            dataset2 = np.ndarray(shape=shape,dtype=np.float32)\n",
    "            dataset3 = np.ndarray(shape=shape_mirna,dtype=np.float32)\n",
    "\n",
    "            i=0\n",
    "            for item in training_list:\n",
    "                img1 = load_img(\"data/\" + path_omics1 + '/' + item, target_size=(122,122), color_mode='grayscale')  # this is a PIL image\n",
    "                img2 = load_img(\"data/\" + path_omics2 + '/' + item, target_size=(122,122), color_mode='grayscale')  # this is a PIL image\n",
    "                # Convert to Numpy Array\n",
    "                x1 = img_to_array(img1) \n",
    "                x2 = img_to_array(img2)  \n",
    "                dataset1[i] = x1\n",
    "                dataset2[i] = x2\n",
    "                i += 1\n",
    "                if i % 100 == 0:\n",
    "                    print(\"%d images to array\" % i)\n",
    "            print(\"All mrna_meth images done!\")\n",
    "\n",
    "        elif self.omics=='mrna_mirna':        #for mRNA and miRNA omics\n",
    "            training_list=np.intersect1d(training_list1,training_list3)\n",
    "            print('mrna_mirna common patients:', len(training_list))\n",
    "            training_list.sort()\n",
    "            training_list = np.asarray(training_list, dtype=object)\n",
    "\n",
    "            shape = (len(training_list), 122, 122, 1)\n",
    "            shape_mirna = (len(training_list), 42, 42, 1)        \n",
    "\n",
    "            dataset1 = np.ndarray(shape=shape,dtype=np.float32)\n",
    "            dataset2 = np.ndarray(shape=shape,dtype=np.float32)\n",
    "            dataset3 = np.ndarray(shape=shape_mirna,dtype=np.float32)\n",
    "\n",
    "            i=0\n",
    "            for item in training_list:\n",
    "                img1 = load_img(\"data/\" + path_omics1 + '/' + item, target_size=(122,122), color_mode='grayscale')  # this is a PIL image\n",
    "                img3 = load_img(\"data/\" + path_omics3 + '/' + item, target_size=(42,42), color_mode='grayscale')  # this is a PIL image\n",
    "                # Convert to Numpy Array\n",
    "                x1 = img_to_array(img1) \n",
    "                x3 = img_to_array(img3)  \n",
    "                dataset1[i] = x1\n",
    "                dataset3[i] = x3\n",
    "                i += 1\n",
    "                if i % 100 == 0:\n",
    "                    print(\"%d images to array\" % i)\n",
    "            print(\"All mrna_mirna images done!\")\n",
    "\n",
    "        elif self.omics=='mrna_meth_mirna':       #for mRNA, Methylation and miRNA omics\n",
    "            training_list = reduce(np.intersect1d, (training_list1, training_list3, training_list2))\n",
    "            training_list.sort()    \n",
    "            print('mrna_meth_mirna common patients:', len(training_list))\n",
    "            training_list = np.asarray(training_list, dtype=object)\n",
    "            #Reference: https://www.kaggle.com/lgmoneda/data-augmentation-regression\n",
    "\n",
    "            shape = (len(training_list), 122, 122, 1)\n",
    "            shape_mirna = (len(training_list), 42, 42, 1)        \n",
    "\n",
    "            dataset1 = np.ndarray(shape=shape,dtype=np.float32)\n",
    "            dataset2 = np.ndarray(shape=shape,dtype=np.float32)\n",
    "            dataset3 = np.ndarray(shape=shape_mirna,dtype=np.float32)\n",
    "\n",
    "            i = 0\n",
    "            for item in training_list:\n",
    "                img1 = load_img(\"data/\" + path_omics1 + '/' + item, target_size=(122,122), color_mode='grayscale')  # this is a PIL image\n",
    "                img2 = load_img(\"data/\" + path_omics2 + '/' + item, target_size=(122,122), color_mode='grayscale')  # this is a PIL image\n",
    "                img3 = load_img(\"data/\" + path_omics3 + '/' + item, target_size=(42,42), color_mode='grayscale')  # this is a PIL image\n",
    "                # Convert to Numpy Array\n",
    "                x1 = img_to_array(img1) \n",
    "                x2 = img_to_array(img2)  \n",
    "                x3 = img_to_array(img3)\n",
    "                #x = x.reshape((3, 120, 160))\n",
    "                # Normalize\n",
    "                #x = (x - 128.0) / 128.0\n",
    "                dataset1[i] = x1\n",
    "                dataset2[i] = x2\n",
    "                dataset3[i] = x3\n",
    "                i += 1\n",
    "                if i % 100 == 0:\n",
    "                    print(\"%d images to array\" % i)\n",
    "            print(\"All mrna_meth_mirna images done!!\")\n",
    "\n",
    "        return dataset1, dataset2, dataset3, training_list\n",
    "\n",
    "    #Data process2\n",
    "    def input_process2(self):\n",
    "        print(\"Data processing-II...\")\n",
    "        sample, t, f, age = [], [], [], []\n",
    "\n",
    "        for list in tqdm(training_list):\n",
    "            for i in range(len(clinical)):\n",
    "                if clinical.iloc[i]['sample'] + '.png' == str(list):\n",
    "                    p_id = clinical.iloc[i]['sample']\n",
    "                    time = clinical.iloc[i]['os_time']\n",
    "                    status = clinical.iloc[i]['vital_status']\n",
    "                    a = clinical.iloc[i]['age']\n",
    "\n",
    "                    sample.append(p_id)\n",
    "                    t.append(time)\n",
    "                    f.append(status)\n",
    "                    age.append(a)\n",
    "                    continue\n",
    "                else:\n",
    "                    pass\n",
    "        t  = np.asarray(t)\n",
    "        f  = np.asarray(f)\n",
    "        sample  = np.asarray(sample)\n",
    "        age = np.asarray(age)\n",
    "\n",
    "        br=np.arange(0.,365.*10,365./4)\n",
    "        nl=len(br)-1\n",
    "        y_t = nnet_survival.make_surv_array(t,f,br)\n",
    "        ind = range(len(f))\n",
    "        print('Done!')\n",
    "\n",
    "        if self.omics=='mrna':\n",
    "            rand_range=[1,2]\n",
    "        if self.omics=='meth':\n",
    "            rand_range=[3,4]\n",
    "        if self.omics=='mirna':\n",
    "            rand_range=[4,5]\n",
    "        if self.omics=='mrna_meth':\n",
    "            rand_range=[6,7]\n",
    "        if self.omics=='mrna_mirna':\n",
    "            rand_range=[8,9]\n",
    "        if self.omics=='mrna_meth_mirna':\n",
    "            rand_range=[10,11]\n",
    "\n",
    "        return t, f, sample, age, br, nl, y_t, ind, rand_range\n",
    "\n",
    "    def train_val_results(self, model):\n",
    "        # Inference: mrna\n",
    "        if self.omics=='mrna':\n",
    "            if self.clinical:\n",
    "                pred_train = model.predict([X_train_mrna, clinical_train], verbose=0, batch_size=batch_size)\n",
    "                pred_val = model.predict([X_test_mrna, clinical_test], verbose=0, batch_size=batch_size)\n",
    "            else:\n",
    "                pred_train = model.predict([X_train_mrna], verbose=0, batch_size=batch_size)\n",
    "                pred_val = model.predict([X_test_mrna], verbose=0, batch_size=batch_size)\n",
    "\n",
    "        # Inference: meth\n",
    "        if self.omics=='meth':\n",
    "            if self.clinical:\n",
    "                pred_train = model.predict([X_train_meth, clinical_train], verbose=0, batch_size=batch_size)\n",
    "                pred_val = model.predict([X_test_meth, clinical_test], verbose=0, batch_size=batch_size)\n",
    "            else:  \n",
    "                pred_train = model.predict([X_train_meth], verbose=0, batch_size=batch_size)\n",
    "                pred_val = model.predict([X_test_meth], verbose=0, batch_size=batch_size)\n",
    "\n",
    "        # Inference: mirna\n",
    "        if self.omics=='mirna':\n",
    "            if self.clinical:\n",
    "                pred_train = model.predict([X_train_mirna, clinical_train], verbose=0, batch_size=batch_size)\n",
    "                pred_val = model.predict([X_test_mirna, clinical_test], verbose=0, batch_size=batch_size)\n",
    "            else:  \n",
    "                pred_train = model.predict([X_train_mirna], verbose=0, batch_size=batch_size)\n",
    "                pred_val = model.predict([X_test_mirna], verbose=0, batch_size=batch_size)\n",
    "\n",
    "        # Inference: mrna+meth\n",
    "        if self.omics=='mrna_meth':\n",
    "            if self.clinical:\n",
    "                pred_train = model.predict([X_train_mrna, X_train_meth, clinical_train], verbose=0, batch_size=batch_size)\n",
    "                pred_val = model.predict([X_test_mrna, X_test_meth, clinical_test], verbose=0, batch_size=batch_size)\n",
    "            else:  \n",
    "                pred_train = model.predict([X_train_mrna,X_train_meth], verbose=0, batch_size=batch_size)\n",
    "                pred_val = model.predict([X_test_mrna, X_test_meth], verbose=0, batch_size=batch_size)\n",
    "\n",
    "        # Inference: mrna+mirna\n",
    "        if self.omics=='mrna_mirna':\n",
    "            if self.clinical:\n",
    "                pred_train = model.predict([X_train_mrna, X_train_mirna, clinical_train], verbose=0, batch_size=batch_size)\n",
    "                pred_val = model.predict([X_test_mrna, X_test_mirna, clinical_test], verbose=0, batch_size=batch_size)\n",
    "            else:  \n",
    "                pred_train = model.predict([X_train_mrna,X_train_mirna], verbose=0, batch_size=batch_size)\n",
    "                pred_val = model.predict([X_test_mrna, X_test_mirna], verbose=0, batch_size=batch_size)\n",
    "\n",
    "        # Inference: mrna+meth+mirna\n",
    "        if self.omics=='mrna_meth_mirna':\n",
    "            if self.clinical:\n",
    "                pred_train = model.predict([X_train_mrna, X_train_meth, X_train_mirna, clinical_train], verbose=0, batch_size=batch_size)\n",
    "                pred_val = model.predict([X_test_mrna, X_test_meth, X_test_mirna, clinical_test], verbose=0, batch_size=batch_size)\n",
    "            else:  \n",
    "                pred_train = model.predict([X_train_mrna, X_train_meth, X_train_mirna], verbose=0, batch_size=batch_size)\n",
    "                pred_val = model.predict([X_test_mrna, X_test_meth, X_test_mirna], verbose=0, batch_size=batch_size)     \n",
    "        return pred_train, pred_val\n",
    "\n",
    "    def surv_prob(self, pred, pred_val, year):\n",
    "        prob = np.cumprod(pred[:,0:np.nonzero(breaks>365*year)[0][0]], axis=1)[:,-1]\n",
    "        prob_val = np.cumprod(pred_val[:,0:np.nonzero(breaks>365*year)[0][0]], axis=1)[:,-1]\n",
    "        median = np.median(prob)\n",
    "        median_val = np.median(prob_val)\n",
    "        #print(\"Training and validation median probabilities are:\", median, median_val)\n",
    "\n",
    "        return prob, prob_val, median, median_val\n",
    "    \n",
    "    def process3(self, clinical, train_list):\n",
    "        print('\\nProcessing clinical features')\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        one_hot_T = pd.DataFrame(enc.fit_transform(clinical[['pathology_T_stage']]).toarray())\n",
    "        one_hot_N = pd.DataFrame(enc.fit_transform(clinical[['pathology_N_stage']]).toarray())\n",
    "        one_hot_M = pd.DataFrame(enc.fit_transform(clinical[['pathology_M_stage']]).toarray())\n",
    "        one_hot_G = pd.DataFrame(enc.fit_transform(clinical[['gender']]).toarray())\n",
    "\n",
    "        clinical_feat = pd.concat([one_hot_T, one_hot_N, one_hot_M, one_hot_G, clinical['age']], axis=1)\n",
    "        clinical_feat = clinical_feat.reset_index(drop=True)\n",
    "        clinical_feat = clinical_feat.set_index([clinical['sample'].values])\n",
    "\n",
    "        train_id = []\n",
    "        for patient in tqdm(training_list):\n",
    "            train_id.append(patient.split('.')[0])\n",
    "        clinical_feat = clinical_feat.loc[train_id,:]\n",
    "        print(\"Features Processed\")\n",
    "\n",
    "        return clinical_feat, train_id\n",
    "\n",
    "\n",
    "    def metrices(self, T, surv_prob, F, y, year, train_val, median):\n",
    "        brier_true = np.cumprod(y[:,0:np.nonzero(breaks>365*year)[0][0]], axis=1)[:,-1]\n",
    "        conc = concordance_index(T, surv_prob, F)\n",
    "        brier = brier_score_loss(brier_true, surv_prob)\n",
    "        \n",
    "        T1 = T[surv_prob >= median]\n",
    "        T2 = T[surv_prob < median]\n",
    "        E1 = F[surv_prob >= median]\n",
    "        E2 = F[surv_prob < median]\n",
    "        result = logrank_test(T1, T2, E1, E2)\n",
    "        p = result.p_value\n",
    "\n",
    "        plt.rc('font', family='serif')\n",
    "        plt.rc('xtick', labelsize='x-small')\n",
    "        plt.rc('ytick', labelsize='x-small')\n",
    "\n",
    "        # fig, ax = plt.subplots(ncols=1, figsize=(8,8))\n",
    "        # #plt.figure(figsize=(12,4))\n",
    "        # #plt.subplot(1,2,1)\n",
    "        # days_plot = 9*365\n",
    "\n",
    "        # kmf = KaplanMeierFitter()\n",
    "        # for i in range(2):\n",
    "        #     if i==0:\n",
    "        #         kmf.fit(T1, event_observed = E1)\n",
    "        #     elif i==1:\n",
    "        #         kmf.fit(T2, event_observed = E2)\n",
    "        #     kmf.plot()  \n",
    "        # N1='N='+ str(len(T1))\n",
    "        # N2='N='+ str(len(T2))\n",
    "\n",
    "        # ax.set_xticks(np.arange(0, days_plot, 365))\n",
    "        # ax.set_yticks(np.arange(0, 1.125, 0.125))\n",
    "        # ax.tick_params(axis='x', labelsize=12)\n",
    "        # ax.tick_params(axis='y', labelsize=12)\n",
    "        # ax.set_xlim([0, days_plot])\n",
    "        # ax.set_ylim([0,1])\n",
    "        # ax.text(50, 0.025, 'logrank p-value = ' +str('%.3g'%(p)), bbox=dict(facecolor='red', alpha=0.3), fontsize=10)\n",
    "\n",
    "        # ax.set_xlabel('Follow-up time (days)', fontsize = 14)\n",
    "        # ax.set_ylabel('Probability of survival', fontsize = 14)\n",
    "        # ax.legend(['Low Risk Individuals ' + N1 ,'High Risk Individuals ' + N2 ])\n",
    "        # ax.set_title('%s set Kaplan-Meier Curves'%(train_val), fontweight = 'bold', fontsize = 14)\n",
    "        # ax.grid()  \n",
    "        # plt.show()\n",
    "\n",
    "        print(\"%s year %s concordance index for %s:\"%(str(year), train_val, str(self.omics)), conc)\n",
    "        print(\"%s year %s brier score for %s:\"%(str(year), train_val, str(self.omics)), brier)\n",
    "        print(\"P-value:\", p)\n",
    "        return conc, brier, p\n",
    "\n",
    "    def ipcw(self, F_train, F_test, T_train, T_test, survival_prob_valid):\n",
    "        struct_train = np.zeros(len(F_train), dtype={'names':('F_train', 'T_train'),'formats':('?','i4')})\n",
    "        struct_test = np.zeros(len(F_test), dtype={'names':('F_test', 'T_test'),'formats':('?','i4')})\n",
    "        struct_train['F_train'] = F_train.astype('bool')\n",
    "        struct_train['T_train'] = T_train\n",
    "        struct_test['F_test'] = F_test.astype('bool')\n",
    "        struct_test['T_test'] = T_test\n",
    "\n",
    "        c_ipcw = '%.5g'%(1-concordance_index_ipcw(struct_train, struct_test, survival_prob_valid)[0])\n",
    "        return c_ipcw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGO = 'tsne'\n",
    "OMICS = 'mrna_meth_mirna'\n",
    "PH = 'PH'\n",
    "# obj = PHOTOMICS('mrna')\n",
    "#obj2 = PHOTOMICS('meth')\n",
    "# obj3 = PHOTOMICS('mirna')\n",
    "#obj = PHOTOMICS('mrna_meth')\n",
    "obj = PHOTOMICS(OMICS, PH=True, clinical=False)\n",
    "#obj = PHOTOMICS('mrna_meth_mirna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical = pd.read_csv('data/clinical_data_subsets/clinical_data.csv')\n",
    "dataset_mrna, dataset_meth, dataset_mirna, training_list = obj.input_process1(ALGO+'_training_data_mrna', ALGO+'_training_data_meth', ALGO+'_training_data_mirna')\n",
    "print(len(dataset_meth),'|', len(dataset_mirna),'|', len(dataset_mrna))\n",
    "t, f, sample, age, breaks, n_intervals, y_train_array, indices, rand_range = obj.input_process2()\n",
    "clinical_feat, train_id_clinical = obj.process3(clinical, training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_mrna), len(dataset_meth), len(dataset_mirna), len(clinical_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'Conc': [], 'Brier': [], 'p_value': [], 'ConcVal': [], 'BrierVal': [], 'PVAlueVal': [], 'ConcBm': [], 'BrierBm': [], 'p_valueBm': [], 'ConcValBm': [], 'BrierValBm': [], 'PVAlueVal_Bm': []})\n",
    "\n",
    "for random in range(20):\n",
    "    seed(123)\n",
    "    tf.random.set_random_seed(123)\n",
    "\n",
    "    #Parameters for model\n",
    "    indices = range(len(f))\n",
    "    #random=3\n",
    "    split_ratio = 0.2\n",
    "    batch_size = 8\n",
    "    sgd  = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=30)\n",
    "    filepath='checkpoints/'+PH+'/'+ALGO+'_'+OMICS+'_clinical/two_dense_weights-improvement-' + str(random) + '.hdf5'\n",
    "    model_checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "    #Initilize and compile model\n",
    "    obj.start_sess()\n",
    "    cox=obj.architecture()\n",
    "    #cox.summary()\n",
    "    cox.compile(loss=nnet_survival.surv_likelihood(n_intervals), optimizer=sgd)\n",
    "\n",
    "    #Test-train split\n",
    "    X_train_mrna, X_test_mrna, y_train, y_test, ind_train_1, ind_test_1 = train_test_split(dataset_mrna, y_train_array,indices, test_size=split_ratio, random_state=random)\n",
    "    X_train_meth, X_test_meth, y_train, y_test, ind_train_2, ind_test_2 = train_test_split(dataset_meth, y_train_array,indices, test_size=split_ratio, random_state=random)\n",
    "    X_train_mirna, X_test_mirna, y_train, y_test, ind_train_2, ind_test_2 = train_test_split(dataset_mirna, y_train_array,indices, test_size=split_ratio, random_state=random)\n",
    "    clinical_train, clinical_test, placeholder_train, placeholder_test, ind_train, ind_test = train_test_split(clinical_feat, y_train_array, indices, test_size=split_ratio, random_state=random)\n",
    "    T_train, T_test, F_train, F_test, TF_ind_train, TF_ind_test = train_test_split(t, f,indices, test_size=split_ratio, random_state=random)\n",
    "\n",
    "    history=cox.fit([X_train_mrna,X_train_meth,X_train_mirna], y_train, batch_size=batch_size, epochs=500, verbose=1, validation_data=([X_test_mrna,X_test_meth,X_test_mirna],y_test), callbacks=[early_stopping,model_checkpoint])\n",
    "\n",
    "    #Load saved best model\n",
    "    if PH==\"PH\":\n",
    "        cox_bm = load_model('checkpoints/'+PH+'/'+ALGO+'_'+OMICS+'_clinical/two_dense_weights-improvement-'+str(random)+'.hdf5', custom_objects={'PropHazards': nnet_survival.PropHazards(n_intervals), 'loss': nnet_survival.surv_likelihood(n_intervals)})\n",
    "    elif PH==\"non-PH\":\n",
    "        cox_bm = load_model('checkpoints/'+PH+'/'+ALGO+'_'+OMICS+'_clinical/two_dense_weights-improvement-'+str(random)+'.hdf5', custom_objects={'loss': nnet_survival.surv_likelihood(n_intervals)})\n",
    "\n",
    "\n",
    "    #Generate training and testing results for last saved and best model\n",
    "    y_pred, y_pred_val=obj.train_val_results(cox)\n",
    "    y_pred_bm, y_pred_val_bm=obj.train_val_results(cox_bm)\n",
    "\n",
    "    #Calculate surv prob and medians for last saved and best model\n",
    "    #Function surv_prob takes three arguments [training prediction(pred_y), validation prediction (y_pred_val), time(t) in years ]\n",
    "    one_year_survival_prob, one_year_survival_prob_val, one_yr_median, one_yr_median_val = obj.surv_prob(y_pred, y_pred_val, 1)\n",
    "    five_year_survival_prob, five_year_survival_prob_val, five_yr_median, five_yr_median_val = obj.surv_prob(y_pred, y_pred_val, 5)\n",
    "\n",
    "    one_year_survival_prob_bm, one_year_survival_prob_val_bm, one_yr_median_bm, one_yr_median_val_bm = obj.surv_prob(y_pred_bm, y_pred_val_bm, 1)\n",
    "    five_year_survival_prob_bm, five_year_survival_prob_val_bm, five_yr_median_bm, five_yr_median_val_bm = obj.surv_prob(y_pred_bm, y_pred_val_bm, 5)\n",
    "\n",
    "    #Calculate concordance index and brier scores for last saved and best model\n",
    "    five_yr_train_concordance, five_yr_train_brier, five_yr_p_value = obj.metrices(T_train, five_year_survival_prob, F_train, y_train, 5, 'train', five_yr_median)\n",
    "    five_yr_val_concordance, five_yr_val_brier, five_yr_p_value_val = obj.metrices(T_test, five_year_survival_prob_val, F_test, y_test, 5, 'test', five_yr_median_val)\n",
    "    five_yr_train_concordance_bm, five_yr_train_brier_bm, five_yr_p_value_bm = obj.metrices(T_train, five_year_survival_prob_bm, F_train, y_train, 5, 'train', five_yr_median_bm)\n",
    "    five_yr_val_concordance_bm, five_yr_val_brier_bm, five_yr_p_value_val_bm = obj.metrices(T_test, five_year_survival_prob_val_bm, F_test, y_test, 5, 'test', five_yr_median_val_bm)\n",
    "\n",
    "    five_yr_ipcw = obj.ipcw(F_train, F_test, T_train, T_test, five_year_survival_prob_val)\n",
    "    five_yr_ipcw_bm = obj.ipcw(F_train, F_test, T_train, T_test, five_year_survival_prob_val_bm)\n",
    "\n",
    "    df = {'Conc': five_yr_train_concordance,'Brier':five_yr_train_brier,'p_value':five_yr_p_value, 'ConcVal': five_yr_val_concordance,'BrierVal':five_yr_val_brier, 'PVAlueVal':five_yr_p_value_val, 'ipcw':five_yr_ipcw, 'ConcBm': five_yr_train_concordance_bm,'BrierBm':five_yr_train_brier_bm,'p_valueBm':five_yr_p_value_bm, 'ConcValBm': five_yr_val_concordance_bm,'BrierValBm':five_yr_val_brier_bm, 'PVAlueVal_Bm':five_yr_p_value_val_bm, 'ipcwBm':five_yr_ipcw_bm}\n",
    "\n",
    "    results = results.append(df, ignore_index=True)\n",
    "    results.to_csv(ALGO+'_models/'+PH+'/'+OMICS+'/res_' + str(random) + '.csv')\n",
    "    obj.reset_keras()\n",
    "results.to_csv(ALGO+'_models/'+PH+'/'+OMICS+'/res_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_train = np.zeros(len(F_train), dtype={'names':('F_train', 'T_train'),'formats':('?','i4')})\n",
    "struct_test = np.zeros(len(F_test), dtype={'names':('F_test', 'T_test'),'formats':('?','i4')})\n",
    "struct_train['F_train'] = F_train.astype('bool')\n",
    "struct_train['T_train'] = T_train\n",
    "struct_test['F_test'] = F_test.astype('bool')\n",
    "struct_test['T_test'] = T_test\n",
    "\n",
    "c_ipcw = '%.5g'%(1-concordance_index_ipcw(struct_train, struct_test, five_year_survival_prob_val)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_ipcw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(struct_train), len(struct_test), len(five_year_survival_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # #One-year\n",
    "    # one_yr_train_concordance, one_yr_train_brier, one_yr_p_value = obj.metrices(T_train, one_year_survival_prob, F_train, y_train, 1, 'train', one_yr_median)\n",
    "    # one_yr_val_concordance, one_yr_val_brier, one_yr_p_value_val = obj.metrices(T_test, one_year_survival_prob_val, F_test, y_test, 1, 'test', one_yr_median_val)\n",
    "    # one_yr_train_concordance_bm, one_yr_train_brier_bm, one_yr_p_value_bm = obj.metrices(T_train, one_year_survival_prob_bm, F_train, y_train, 1, 'train', one_yr_median_bm) \n",
    "    # one_yr_val_concordance_bm, one_yr_val_brier_bm, one_yr_p_value_val_bm = obj.metrices(T_test, one_year_survival_prob_val_bm, F_test, y_test, 1, 'test', one_yr_median_val_bm)\n",
    "    #Five-year"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bit3de122227a47471280c7d82aa4556c4e",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}